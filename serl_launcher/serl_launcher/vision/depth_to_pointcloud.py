"""
æ·±åº¦å›¾åˆ°ç¨€ç–ç‚¹äº‘è½¬æ¢æ¨¡å—
ç”¨äºå°†æ·±åº¦å›¾åƒè½¬æ¢ä¸ºSegNN encoderå¯ä»¥å¤„ç†çš„ç‚¹äº‘æ ¼å¼
"""
import sys
import os
import jax
import jax.numpy as jnp
from typing import Tuple, Optional, Dict
import flax.linen as nn

# æ·»åŠ SegNNæ¨¡å—è·¯å¾„ä»¥ä½¿ç”¨FPS
sys.path.append('/home/hanyu/code/Seg-NN')
from pointnet2_ops.fps_jax import furthest_point_sampling

class DepthToPointCloud(nn.Module):
    """
    å°†æ·±åº¦å›¾è½¬æ¢ä¸ºç¨€ç–ç‚¹äº‘çš„æ¨¡å— - å•é˜¶æ®µFPSé‡‡æ ·ç­–ç•¥

    Args:
        max_points: æœ€ç»ˆè¾“å‡ºç‚¹æ•° (ä¸SegNN input_pointsåŒ¹é…)
        min_depth: æœ€å°æ·±åº¦å€¼ (ç±³)
        max_depth: æœ€å¤§æ·±åº¦å€¼ (ç±³)
        add_noise: æ˜¯å¦æ·»åŠ å™ªå£°å¢å¼º
    """
    max_points: int = 2048           # æœ€ç»ˆè¾“å‡ºç‚¹æ•° ä¸segnnåŒ¹é…
    min_depth: float = 0.1
    max_depth: float = 2.0
    add_noise: bool = False
    noise_std: float = 0.002  # 2mmæ ‡å‡†å·®

    def setup(self):
        # ç›¸æœºå†…å‚ (è¿™äº›åº”è¯¥ä»é…ç½®ä¸­è¯»å–)
        # é»˜è®¤ä¸ºRealSense D435çš„å‚æ•°
        self.fx = None
        self.fy = None
        self.cx = None
        self.cy = None

    def depth_to_xyz(self, depth_image: jnp.ndarray) -> jnp.ndarray:
        """
        å°†æ·±åº¦å›¾è½¬æ¢ä¸º3Dç‚¹åæ ‡

        Args:
            depth_image: [H, W] æ·±åº¦å›¾ (ä»¥ç±³ä¸ºå•ä½)

        Returns:
            xyz: [H*W, 3] 3Dåæ ‡
        """
        H, W = depth_image.shape

        # åˆ›å»ºåƒç´ åæ ‡ç½‘æ ¼
        u, v = jnp.meshgrid(jnp.arange(W), jnp.arange(H), indexing='xy')
        u = u.flatten().astype(jnp.float32)
        v = v.flatten().astype(jnp.float32)
        depth = depth_image.flatten()

        # æ·±åº¦å›¾åˆ°3Dåæ ‡è½¬æ¢
        # x = (u - cx) * depth / fx
        # y = (v - cy) * depth / fy
        # z = depth
        x = (u - self.cx) * depth / self.fx
        y = (v - self.cy) * depth / self.fy
        z = depth

        xyz = jnp.stack([x, y, z], axis=1)  # [H*W, 3]
        return xyz

    def extract_rgb_at_points(self, rgb_image: jnp.ndarray) -> jnp.ndarray:
        """
        ä»RGBå›¾åƒä¸­æå–å¯¹åº”ç‚¹çš„é¢œè‰²ä¿¡æ¯

        Args:
            rgb_image: [H, W, 3] RGBå›¾åƒ [0, 255]

        Returns:
            rgb: [H*W, 3] RGBå€¼ [0, 1]
        """
        # å°†RGBå›¾åƒé‡å¡‘å¹¶å½’ä¸€åŒ–åˆ°[0,1]
        rgb = rgb_image.reshape(-1, 3) / 255.0
        return rgb

    def filter_valid_points(self, xyz: jnp.ndarray, rgb: jnp.ndarray,
                          depth_image: jnp.ndarray) -> Tuple[jnp.ndarray, jnp.ndarray]:
        """
        è¿‡æ»¤æœ‰æ•ˆçš„3Dç‚¹ (ç§»é™¤æ— æ•ˆæ·±åº¦å’Œè¶…å‡ºèŒƒå›´çš„ç‚¹)
        ä½¿ç”¨jnp.whereé¿å…åŠ¨æ€boolean indexing

        Args:
            xyz: [N, 3] 3Dåæ ‡
            rgb: [N, 3] RGBå€¼
            depth_image: [H, W] æ·±åº¦å›¾

        Returns:
            valid_xyz: [N, 3] æœ‰æ•ˆ3Dåæ ‡ï¼ˆæ— æ•ˆç‚¹è®¾ä¸ºinfï¼‰
            valid_rgb: [N, 3] æœ‰æ•ˆRGBå€¼ï¼ˆæ— æ•ˆç‚¹è®¾ä¸º0ï¼‰
        """
        depth_flat = depth_image.flatten()

        # åˆ›å»ºæœ‰æ•ˆæ€§æ©ç 
        valid_mask = (
            (depth_flat > self.min_depth) &  # æœ€å°æ·±åº¦
            (depth_flat < self.max_depth) &  # æœ€å¤§æ·±åº¦
            (depth_flat > 0) &               # éé›¶æ·±åº¦
            jnp.isfinite(depth_flat)         # æœ‰é™å€¼
        )

        # ä½¿ç”¨jnp.whereæ›¿æ¢æ— æ•ˆç‚¹ï¼Œè€Œä¸æ˜¯boolean indexing
        # æ— æ•ˆç‚¹çš„xyzè®¾ä¸ºinfï¼Œè¿™æ ·åœ¨FPSé‡‡æ ·æ—¶ä¼šè¢«è‡ªåŠ¨å¿½ç•¥
        valid_mask_3d = jnp.expand_dims(valid_mask, axis=-1)
        valid_xyz = jnp.where(valid_mask_3d, xyz, jnp.inf)
        valid_rgb = jnp.where(valid_mask_3d, rgb, 0.0)

        return valid_xyz, valid_rgb

    def fps_sample(self, xyz: jnp.ndarray, rgb: jnp.ndarray,
                   key: jax.random.PRNGKey) -> Tuple[jnp.ndarray, jnp.ndarray]:
        """
        å•é˜¶æ®µFPSé‡‡æ ·: ç›´æ¥ä»æœ‰æ•ˆç‚¹FPSé‡‡æ ·åˆ°max_pointsæ•°é‡

        Args:
            xyz: [N, 3] 3Dåæ ‡
            rgb: [N, 3] RGBå€¼
            key: éšæœºæ•°ç§å­

        Returns:
            sampled_xyz: [max_points, 3] é‡‡æ ·åçš„3Dåæ ‡
            sampled_rgb: [max_points, 3] é‡‡æ ·åçš„RGBå€¼
        """
        N = xyz.shape[0]

        if N == 0:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç‚¹ï¼Œè¿”å›é›¶å‘é‡
            return (jnp.zeros((self.max_points, 3)),
                   jnp.zeros((self.max_points, 3)))

        # å•é˜¶æ®µFPSé‡‡æ ·
        if N >= self.max_points:
            # è¶³å¤Ÿç‚¹æ•°ï¼Œä½¿ç”¨FPS
            xyz_batch = xyz[None, ...].astype(jnp.float32)  # [1, N, 3]
            indices = furthest_point_sampling(xyz_batch, self.max_points)  # [1, max_points]
            indices = indices[0]  # [max_points]
        else:
            # ç‚¹æ•°ä¸è¶³ï¼Œéšæœºé‡å¤é‡‡æ ·
            indices = jax.random.choice(key, N, (self.max_points,), replace=True)

        sampled_xyz = xyz[indices]
        sampled_rgb = rgb[indices]

        return sampled_xyz, sampled_rgb


    def add_coordinate_normalization(self, xyz: jnp.ndarray) -> jnp.ndarray:
        """
        æ·»åŠ å½’ä¸€åŒ–åæ ‡ (æŒ‰SegNNè¦æ±‚)

        Args:
            xyz: [N, 3] åŸå§‹åæ ‡

        Returns:
            XYZ: [N, 3] å½’ä¸€åŒ–åæ ‡ [0,1]
        """
        # å»ä¸­å¿ƒåŒ–
        xyz_min = jnp.min(xyz, axis=0, keepdims=True)
        xyz_centered = xyz - xyz_min

        # å½’ä¸€åŒ–åˆ°[0,1]
        xyz_max = jnp.max(xyz_centered, axis=0, keepdims=True)
        xyz_max = jnp.where(xyz_max < 1e-8, 1.0, xyz_max)  # é¿å…é™¤é›¶
        XYZ = xyz_centered / xyz_max

        return XYZ

    @nn.compact
    def __call__(self, depth_image: jnp.ndarray, rgb_image: jnp.ndarray,
                 key: jax.random.PRNGKey, train: bool = False) -> jnp.ndarray:
        """
        ä¸»è½¬æ¢å‡½æ•°

        Args:
            depth_image: [H, W] æ·±åº¦å›¾ (ç±³)
            rgb_image: [H, W, 3] RGBå›¾åƒ [0, 255]
            key: éšæœºæ•°ç§å­
            train: è®­ç»ƒæ¨¡å¼

        Returns:
            pointcloud: [max_points, 9] ç‚¹äº‘ (xyz + rgb + XYZ)
        """
        # 1. æ·±åº¦å›¾è½¬3Dåæ ‡
        xyz = self.depth_to_xyz(depth_image)

        # 2. æå–RGB
        rgb = self.extract_rgb_at_points(rgb_image)

        # 3. è¿‡æ»¤æœ‰æ•ˆç‚¹
        valid_xyz, valid_rgb = self.filter_valid_points(xyz, rgb, depth_image)

        # 4. FPSé‡‡æ ·
        sampled_xyz, sampled_rgb = self.fps_sample(valid_xyz, valid_rgb, key)

        # 5. æ·»åŠ å™ªå£° (è®­ç»ƒæ—¶)
        if self.add_noise and train:
            noise_key, key = jax.random.split(key)
            noise = jax.random.normal(noise_key, sampled_xyz.shape) * self.noise_std
            sampled_xyz = sampled_xyz + noise

        # 6. åˆ›å»ºå½’ä¸€åŒ–åæ ‡
        XYZ = self.add_coordinate_normalization(sampled_xyz)

        # 7. æŒ‰SegNNæ ¼å¼ç»„åˆ: [xyz, rgb, XYZ]
        pointcloud = jnp.concatenate([sampled_xyz, sampled_rgb, XYZ], axis=1)

        return pointcloud


def create_depth_converter(camera_params: Optional[Dict[str, float]] = None,
                          max_points: int = 4096) -> DepthToPointCloud:
    """
    åˆ›å»ºæ·±åº¦è½¬æ¢å™¨çš„å·¥å‚å‡½æ•°

    Args:
        camera_params: ç›¸æœºå†…å‚å­—å…¸ {'fx', 'fy', 'cx', 'cy'}
        max_points: æœ€å¤§ç‚¹æ•°

    Returns:
        DepthToPointCloudå®ä¾‹
    """
    converter = DepthToPointCloud(max_points=max_points)

    if camera_params:
        converter.fx = camera_params.get('fx', 615.0)
        converter.fy = camera_params.get('fy', 615.0)
        converter.cx = camera_params.get('cx', 320.0)
        converter.cy = camera_params.get('cy', 240.0)

    return converter


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ”§ æµ‹è¯•æ·±åº¦å›¾åˆ°ç‚¹äº‘è½¬æ¢")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    key = jax.random.PRNGKey(42)
    H, W = 480, 640

    # æ¨¡æ‹Ÿæ·±åº¦å›¾ (0.5-1.5ç±³éšæœºæ·±åº¦)
    depth_key, rgb_key, test_key = jax.random.split(key, 3)
    depth = jax.random.uniform(depth_key, (H, W), minval=0.5, maxval=1.5)
    rgb = jax.random.uniform(rgb_key, (H, W, 3), minval=0, maxval=255)

    # åˆ›å»ºè½¬æ¢å™¨
    converter = create_depth_converter(max_points=2048)

    # æ­£ç¡®çš„Flaxæ¨¡å—ä½¿ç”¨æ–¹å¼ï¼šåˆå§‹åŒ–å‚æ•°
    dummy_depth = jnp.ones((H, W))
    dummy_rgb = jnp.ones((H, W, 3))
    init_key, apply_key = jax.random.split(test_key)

    # åˆå§‹åŒ–å‚æ•°ï¼ˆè™½ç„¶è¿™ä¸ªæ¨¡å—æ²¡æœ‰å¯å­¦ä¹ å‚æ•°ï¼‰
    params = converter.init(init_key, dummy_depth, dummy_rgb, apply_key)

    # ä½¿ç”¨applyæ–¹æ³•æ‰§è¡Œè½¬æ¢
    pointcloud = converter.apply(params, depth, rgb, apply_key)

    print(f"âœ“ è¾“å…¥æ·±åº¦å›¾å½¢çŠ¶: {depth.shape}")
    print(f"âœ“ è¾“å…¥RGBå›¾å½¢çŠ¶: {rgb.shape}")
    print(f"âœ“ è¾“å‡ºç‚¹äº‘å½¢çŠ¶: {pointcloud.shape}")
    print(f"âœ“ ç‚¹äº‘èŒƒå›´:")
    print(f"  - xyz: [{jnp.min(pointcloud[:, :3]):.3f}, {jnp.max(pointcloud[:, :3]):.3f}]")
    print(f"  - rgb: [{jnp.min(pointcloud[:, 3:6]):.3f}, {jnp.max(pointcloud[:, 3:6]):.3f}]")
    print(f"  - XYZ: [{jnp.min(pointcloud[:, 6:9]):.3f}, {jnp.max(pointcloud[:, 6:9]):.3f}]")

    print("\nğŸ¯ è½¬æ¢æˆåŠŸ! ç‚¹äº‘æ ¼å¼ç¬¦åˆSegNNè¦æ±‚")
"""
å¤šæ¨¡æ€ç¼–ç å™¨ï¼šæ”¯æŒå¤šç›¸æœºRGB + æ·±åº¦ç‚¹äº‘çš„å¹¶è¡Œå¤„ç†
æ¯ä¸ªç›¸æœºéƒ½æœ‰ç‹¬ç«‹çš„RGBå’Œæ·±åº¦ç¼–ç å™¨
"""
from typing import Dict, Iterable
import flax.linen as nn
import jax
import jax.numpy as jnp
from einops import rearrange

from serl_launcher.vision.segnn_encoder import SegNNEncoder


class MultiModalEncodingWrapper(nn.Module):
    """
    å¤šæ¨¡æ€ç¼–ç åŒ…è£…å™¨ï¼šå¤šç›¸æœºRGB + æ·±åº¦ + çŠ¶æ€

    Args:
        rgb_encoder: RGBç¼–ç å™¨å­—å…¸ {camera_name: encoder}
        depth_encoder: æ·±åº¦ç¼–ç å™¨å­—å…¸ {camera_name: segnn_encoder}
        use_proprio: æ˜¯å¦ä½¿ç”¨æœ¬ä½“æ„Ÿè§‰
        proprio_latent_dim: æœ¬ä½“æ„Ÿè§‰æ½œåœ¨ç»´åº¦
        enable_stacking: æ˜¯å¦å¯ç”¨å †å 
        camera_keys: ç›¸æœºåç§°åˆ—è¡¨ ['wrist_1', 'front', 'side']
    """
    rgb_encoder: Dict[str, nn.Module]     # {camera_name: rgb_encoder}
    depth_encoder: Dict[str, SegNNEncoder]  # {camera_name: depth_encoder}
    use_proprio: bool = False
    proprio_latent_dim: int = 64
    enable_stacking: bool = False
    camera_keys: Iterable[str] = ("wrist_1", "front", "side")

    @nn.compact
    def __call__(
        self,
        observations: Dict[str, jnp.ndarray],
        train: bool = False,
        stop_gradient: bool = False,
        is_encoded: bool = False,
    ) -> jnp.ndarray:
        """
        å¤šæ¨¡æ€ç¼–ç 

        æœŸæœ›çš„è§‚æµ‹æ ¼å¼ï¼š
        - RGB: 'wrist_1', 'front', 'side' ç­‰
        - æ·±åº¦: 'depth_wrist_1', 'depth_front', 'depth_side' ç­‰
        - çŠ¶æ€: 'state'
        """
        encoded_features = []

        # éå†æ¯ä¸ªç›¸æœº
        for camera_name in self.camera_keys:
            camera_features = []

            # 1. RGBç¼–ç ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if camera_name in observations and camera_name in self.rgb_encoder:
                rgb_image = observations[camera_name]

                # æ£€æŸ¥æ˜¯å¦æ˜¯RGBDæ ¼å¼ï¼Œå¦‚æœæ˜¯åˆ™æ‹†åˆ†RGB
                if len(rgb_image.shape) >= 3 and rgb_image.shape[-1] == 4:
                    # 4é€šé“æ•°æ®ï¼Œæ‹†åˆ†RGBå’Œæ·±åº¦
                    rgb_image = rgb_image[..., :3]  # å–å‰3ä¸ªé€šé“ä½œä¸ºRGB
                    # print(f"æ£€æµ‹åˆ°4é€šé“æ•°æ®ï¼Œè‡ªåŠ¨æ‹†åˆ†RGB: {rgb_image.shape}")

                if not is_encoded and self.enable_stacking:
                    # å¤„ç†æ—¶åºå †å 
                    if len(rgb_image.shape) == 4:
                        rgb_image = rearrange(rgb_image, "T H W C -> H W (T C)")
                    elif len(rgb_image.shape) == 5:
                        rgb_image = rearrange(rgb_image, "B T H W C -> B H W (T C)")

                # RGBç¼–ç 
                rgb_features = self.rgb_encoder[camera_name](
                    rgb_image, train=train, encode=not is_encoded
                )

                if stop_gradient:
                    rgb_features = jax.lax.stop_gradient(rgb_features)

                camera_features.append(rgb_features)
                # print(f"RGB {camera_name}: {rgb_features.shape}")

            # 2. æ·±åº¦ç¼–ç 
            depth_key = f"depth_{camera_name}"
            has_separate_depth = depth_key in observations
            has_rgbd_data = (camera_name in observations and
                           len(observations[camera_name].shape) >= 3 and
                           observations[camera_name].shape[-1] == 4)

            if ((has_separate_depth or has_rgbd_data) and
                camera_name in observations and
                camera_name in self.depth_encoder):

                if has_separate_depth:
                    # ç‹¬ç«‹æ·±åº¦æ•°æ®
                    depth_image = observations[depth_key]
                    rgb_for_depth = observations[camera_name]
                    if len(rgb_for_depth.shape) >= 3 and rgb_for_depth.shape[-1] == 4:
                        rgb_for_depth = rgb_for_depth[..., :3]  # æå–RGBéƒ¨åˆ†
                else:
                    # ä»4é€šé“RGBDæ•°æ®ä¸­æå–æ·±åº¦
                    rgbd_data = observations[camera_name]
                    depth_image = rgbd_data[..., 3]  # ç¬¬4ä¸ªé€šé“æ˜¯æ·±åº¦
                    rgb_for_depth = rgbd_data[..., :3]  # å‰3ä¸ªé€šé“æ˜¯RGB
                    # print(f"ä»RGBDæ•°æ®æå–æ·±åº¦: depth={depth_image.shape}, rgb={rgb_for_depth.shape}")

                # æ·±åº¦ç‚¹äº‘ç¼–ç 
                depth_features = self.depth_encoder[camera_name](
                    depth_image, rgb_for_depth, train=train
                )

                if stop_gradient:
                    depth_features = jax.lax.stop_gradient(depth_features)

                camera_features.append(depth_features)
                # print(f"Depth {camera_name}: {depth_features.shape}")

            # 3. åˆå¹¶è¯¥ç›¸æœºçš„ç‰¹å¾
            if camera_features:
                # print(f"Camera {camera_name} has {len(camera_features)} features")
                if len(camera_features) == 1:
                    camera_encoded = camera_features[0]
                else:
                    # print(f"Concatenating features: {[f.shape for f in camera_features]}")

                    # ç¡®ä¿æ‰€æœ‰ç‰¹å¾å…·æœ‰ç›¸åŒçš„batchç»´åº¦
                    normalized_features = []
                    target_ndim = max(len(f.shape) for f in camera_features)

                    for feat in camera_features:
                        if len(feat.shape) < target_ndim:
                            # ä¸ºç¼ºå°‘batchç»´åº¦çš„ç‰¹å¾æ·»åŠ batchç»´åº¦
                            feat = jnp.expand_dims(feat, axis=0)
                        normalized_features.append(feat)

                    # print(f"Normalized features: {[f.shape for f in normalized_features]}")
                    camera_encoded = jnp.concatenate(normalized_features, axis=-1)
                    # print(f"Camera {camera_name} encoded: {camera_encoded.shape}")
                encoded_features.append(camera_encoded)

        # 4. æœ¬ä½“æ„Ÿè§‰ç¼–ç ï¼ˆå¯é€‰ï¼‰
        if self.use_proprio and 'state' in observations:
            state = observations['state']

            if self.enable_stacking:
                if len(state.shape) == 2:
                    state = rearrange(state, "T C -> (T C)")
                    # è°ƒæ•´å…¶ä»–ç‰¹å¾çš„å½¢çŠ¶ä»¥åŒ¹é…
                    encoded_features = [f.reshape(-1) if len(f.shape) > 1 else f
                                      for f in encoded_features]
                elif len(state.shape) == 3:
                    state = rearrange(state, "B T C -> B (T C)")
            else:
                # ä¸å¯ç”¨stackingæ—¶ï¼Œç¡®ä¿çŠ¶æ€ç»´åº¦ä¸ç›¸æœºç‰¹å¾åŒ¹é…
                if len(state.shape) == 3:
                    # [B, T, C] â†’ [B, T*C] (å–æœ€åä¸€å¸§æˆ–flatten)
                    state = state[:, -1, :]  # å–æœ€åä¸€å¸§: [B, T, C] â†’ [B, C]

            # çŠ¶æ€ç¼–ç 
            state_features = nn.Dense(
                self.proprio_latent_dim,
                kernel_init=nn.initializers.xavier_uniform()
            )(state)
            state_features = nn.LayerNorm()(state_features)
            state_features = nn.tanh(state_features)
            encoded_features.append(state_features)

        # 5. ç‰¹å¾èåˆ
        if len(encoded_features) == 0:
            raise ValueError("No valid modalities found in observations")

        # ç¡®ä¿ç‰¹å¾å½¢çŠ¶å…¼å®¹
        if len(encoded_features) > 1:
            # è·å–å‚è€ƒå½¢çŠ¶ï¼ˆé™¤äº†æœ€åä¸€ç»´ï¼‰
            reference_shape = encoded_features[0].shape[:-1]
            adjusted_features = []

            for feat in encoded_features:
                if feat.shape[:-1] != reference_shape:
                    # å¤„ç†ç»´åº¦ä¸åŒ¹é…
                    if feat.ndim == 1 and len(reference_shape) > 0:
                        # æ‰©å±•1Dç‰¹å¾
                        feat = jnp.expand_dims(feat, axis=0)
                        if feat.shape[:-1] != reference_shape:
                            feat = jnp.broadcast_to(feat, reference_shape + (feat.shape[-1],))
                adjusted_features.append(feat)

            encoded_features = adjusted_features

        # æœ€ç»ˆæ‹¼æ¥
        encoded = jnp.concatenate(encoded_features, axis=-1)
        return encoded


def create_multimodal_encoder(
    rgb_encoder_dict: Dict[str, nn.Module],
    depth_encoder_dict: Dict[str, SegNNEncoder],
    use_proprio: bool = False,
    camera_keys: Iterable[str] = ("wrist_1", "front", "side"),
) -> MultiModalEncodingWrapper:
    """
    åˆ›å»ºå¤šæ¨¡æ€ç¼–ç å™¨å·¥å‚å‡½æ•°

    Args:
        rgb_encoder_dict: RGBç¼–ç å™¨å­—å…¸ {camera_name: encoder}
        depth_encoder_dict: æ·±åº¦ç¼–ç å™¨å­—å…¸ {camera_name: segnn_encoder}
        use_proprio: æ˜¯å¦ä½¿ç”¨çŠ¶æ€ä¿¡æ¯
        camera_keys: ç›¸æœºåç§°åˆ—è¡¨

    Returns:
        å¤šæ¨¡æ€ç¼–ç å™¨
    """
    return MultiModalEncodingWrapper(
        rgb_encoder=rgb_encoder_dict,
        depth_encoder=depth_encoder_dict,
        use_proprio=use_proprio,
        enable_stacking=True,
        camera_keys=camera_keys
    )


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•å¤šç›¸æœºå¤šæ¨¡æ€ç¼–ç å™¨")

    # æ¨¡æ‹Ÿç¼–ç å™¨ - ç¡®ä¿è¾“å‡ºå½¢çŠ¶ä¸€è‡´
    class MockRGBEncoder(nn.Module):
        @nn.compact
        def __call__(self, x, train=False, encode=True):
            print(f"RGB encoder input shape: {x.shape}")
            if encode:
                # æ¨¡æ‹ŸResNetè¾“å‡ºï¼Œä¿æŒbatchç»´åº¦
                batch_size = x.shape[0]
                print(f"RGB encoder batch size: {batch_size}")
                x_flat = x.reshape(batch_size, -1)
                print(f"RGB encoder flattened shape: {x_flat.shape}")
                features = nn.Dense(256)(x_flat)
                print(f"RGB encoder output shape: {features.shape}")
                return features
            return x

    class MockDepthEncoder(nn.Module):
        @nn.compact
        def __call__(self, depth, rgb, train=False):
            # æ¨¡æ‹ŸSegNNè¾“å‡ºï¼Œå¤„ç†æ—¶åºç»´åº¦ [B,T,H,W] â†’ [B,C]
            batch_size = depth.shape[0]
            print(f"Depth encoder input shapes: depth={depth.shape}, rgb={rgb.shape}")
            print(f"Depth encoder batch size: {batch_size}")
            # å¦‚æœæœ‰æ—¶åºç»´åº¦ï¼Œå–æœ€åä¸€å¸§ (æ¨¡æ‹Ÿå®é™…SegNNå¤„ç†)
            if len(depth.shape) == 4:
                depth = depth[:, -1, :, :]  # [B,T,H,W] â†’ [B,H,W]
            if len(rgb.shape) == 5:
                rgb = rgb[:, -1, :, :, :]  # [B,T,H,W,C] â†’ [B,H,W,C]
            # åˆ›å»ºæ­£ç¡®çš„è¾“å…¥å½¢çŠ¶
            dummy_input = jnp.ones((batch_size, 64))
            features = nn.Dense(128)(dummy_input)
            print(f"Depth encoder output shape: {features.shape}")
            return features

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    key = jax.random.PRNGKey(42)
    batch_size = 2
    cameras = ["wrist_1", "front", "side"]

    # æ¨¡æ‹ŸçœŸå®HIL-SERLæ•°æ®æµï¼šChunkingWrapper(obs_horizon=1) + æ‰¹å¤„ç†
    observations = {
        # RGBå›¾åƒï¼š5ç»´ [B, T=1, H, W, C] (ChunkingWrapperè¾“å‡º)
        "wrist_1": jax.random.normal(key, (batch_size, 1, 128, 128, 3)),
        "front": jax.random.normal(key, (batch_size, 1, 128, 128, 3)),
        "side": jax.random.normal(key, (batch_size, 1, 128, 128, 3)),
        # æ·±åº¦å›¾åƒï¼š4ç»´ [B, T=1, H, W]
        "depth_wrist_1": jax.random.normal(key, (batch_size, 1, 128, 128)),
        "depth_front": jax.random.normal(key, (batch_size, 1, 128, 128)),
        "depth_side": jax.random.normal(key, (batch_size, 1, 128, 128)),
        # çŠ¶æ€ï¼š3ç»´ [B, T=1, C]
        "state": jax.random.normal(key, (batch_size, 1, 10))
    }

    # åˆ›å»ºç¼–ç å™¨å­—å…¸
    rgb_encoders = {cam: MockRGBEncoder() for cam in cameras}
    depth_encoders = {cam: MockDepthEncoder() for cam in cameras}

    # åˆ›å»ºç¼–ç å™¨ï¼Œä½¿ç”¨æ­£ç¡®çš„5ç»´æ—¶åºæ•°æ®æµ‹è¯•stacking
    encoder = MultiModalEncodingWrapper(
        rgb_encoder=rgb_encoders,
        depth_encoder=depth_encoders,
        use_proprio=True,
        enable_stacking=True,  # ç°åœ¨ä½¿ç”¨5ç»´æ•°æ®ï¼Œåº”è¯¥æ­£ç¡®å¤„ç†
        camera_keys=cameras
    )

    # æµ‹è¯•
    params = encoder.init(key, observations, train=True)
    features = encoder.apply(params, observations, train=True)

    print(f"âœ“ ç›¸æœºæ•°é‡: {len(cameras)}")
    print(f"âœ“ RGBè¾“å…¥å½¢çŠ¶: {[observations[cam].shape for cam in cameras]}")
    print(f"âœ“ æ·±åº¦è¾“å…¥å½¢çŠ¶: {[observations[f'depth_{cam}'].shape for cam in cameras]}")
    print(f"âœ“ è¾“å‡ºç‰¹å¾å½¢çŠ¶: {features.shape}")
    print("ğŸ¯ å¤šç›¸æœºå¤šæ¨¡æ€ç¼–ç å™¨æµ‹è¯•æˆåŠŸ!")
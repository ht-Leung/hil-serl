"""
SegNN Encoder for HIL-SERL
å°†SegNNç‚¹äº‘ç¼–ç å™¨é›†æˆåˆ°SERLæ¡†æ¶ä¸­ï¼Œä½œä¸ºç¬¬ä¸‰å¹¶è¡Œåˆ†æ”¯
"""
import sys
import jax
import jax.numpy as jnp
import flax.linen as nn
from typing import Optional

# æ·»åŠ SegNNæ¨¡å—è·¯å¾„
sys.path.append('/home/hanyu/code/Seg-NN')
from models.encoder_jax_optimized import Encoder_Seg_Optimized

from serl_launcher.vision.depth_to_pointcloud import DepthToPointCloud


class CustomDepthConverter(DepthToPointCloud):
    """
    å¸¦ç›¸æœºå‚æ•°çš„è‡ªå®šä¹‰æ·±åº¦è½¬æ¢å™¨
    """
    camera_fx: float = 615.0
    camera_fy: float = 615.0
    camera_cx: float = 320.0
    camera_cy: float = 240.0

    def setup(self):
        # åœ¨setupä¸­è®¾ç½®ç›¸æœºå‚æ•°
        self.fx = self.camera_fx
        self.fy = self.camera_fy
        self.cx = self.camera_cx
        self.cy = self.camera_cy


class SegNNEncoder(nn.Module):
    """
    SegNNç‚¹äº‘ç¼–ç å™¨ï¼Œç”¨äºå¤„ç†æ·±åº¦+RGBå›¾åƒ

    Args:
        input_points: SegNNç¼–ç å™¨çš„è¾“å…¥ç‚¹æ•°
        num_stages: SegNNç¼–ç å™¨çš„é˜¶æ®µæ•°
        embed_dim: SegNNç¼–ç å™¨çš„åµŒå…¥ç»´åº¦
        k_neighbors: Kè¿‘é‚»æ•°é‡
        de_neighbors: è§£ç è¿‘é‚»æ•°
        bottleneck_dim: è¾“å‡ºç“¶é¢ˆç»´åº¦
        depth_params: æ·±åº¦è½¬æ¢å™¨å‚æ•°å­—å…¸
    """
    input_points: int = 2048
    num_stages: int = 3
    embed_dim: int = 72
    k_neighbors: int = 32
    de_neighbors: int = 6
    alpha: float = 1000
    beta: float = 50
    bottleneck_dim: Optional[int] = 256

    # æ·±åº¦è½¬æ¢å™¨å‚æ•°
    min_depth: float = 0.1
    max_depth: float = 2.0
    camera_fx: float = 615.0
    camera_fy: float = 615.0
    camera_cx: float = 320.0
    camera_cy: float = 240.0

    def setup(self):
        # åˆ›å»ºæ·±åº¦è½¬æ¢å™¨ï¼ˆç›¸æœºå‚æ•°é€šè¿‡è‡ªå®šä¹‰ç±»ä¼ é€’ï¼‰
        self.depth_converter = CustomDepthConverter(
            max_points=self.input_points,
            min_depth=self.min_depth,
            max_depth=self.max_depth,
            camera_fx=self.camera_fx,
            camera_fy=self.camera_fy,
            camera_cx=self.camera_cx,
            camera_cy=self.camera_cy,
            add_noise=False
        )

        # åˆ›å»ºSegNNç¼–ç å™¨
        self.segnn_encoder = Encoder_Seg_Optimized(
            input_points=self.input_points,
            num_stages=self.num_stages,
            embed_dim=self.embed_dim,
            k_neighbors=self.k_neighbors,
            de_neighbors=self.de_neighbors,
            alpha=self.alpha,
            beta=self.beta
        )

        # æ·»åŠ ç“¶é¢ˆå±‚
        if self.bottleneck_dim is not None:
            self.bottleneck = nn.Dense(self.bottleneck_dim)
            self.layer_norm = nn.LayerNorm()

    @nn.compact
    def __call__(self, depth_image: jnp.ndarray, rgb_image: jnp.ndarray,
                 train: bool = False) -> jnp.ndarray:
        """
        å‰å‘ä¼ æ’­

        Args:
            depth_image: [H, W] æˆ– [B, H, W] æ·±åº¦å›¾
            rgb_image: [H, W, 3] æˆ– [B, H, W, 3] RGBå›¾åƒ
            train: è®­ç»ƒæ¨¡å¼

        Returns:
            features: [bottleneck_dim] æˆ– [B, bottleneck_dim] ç‚¹äº‘ç‰¹å¾
        """
        # ç”Ÿæˆéšæœºç§å­ç”¨äºç‚¹äº‘é‡‡æ ·
        if train:
            # è®­ç»ƒæ—¶ä½¿ç”¨éšæœºç§å­
            key = self.make_rng('pointcloud_sampling')
        else:
            # æ¨ç†æ—¶ä½¿ç”¨å›ºå®šç§å­ä¿è¯ä¸€è‡´æ€§
            key = jax.random.PRNGKey(42)

        # å¤„ç†batchå’Œæ—¶åºç»´åº¦
        if len(depth_image.shape) == 4:
            # [B, T, H, W] -> å–ç¬¬ä¸€ä¸ªæ ·æœ¬å’Œæœ€åä¸€å¸§
            batch_size = depth_image.shape[0]
            depth_image_single = depth_image[0, -1]  # [H, W]
            rgb_image_single = rgb_image[0, -1]      # [H, W, 3]
        elif len(depth_image.shape) == 3:
            # [B, H, W] -> å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            batch_size = depth_image.shape[0]
            depth_image_single = depth_image[0]  # [H, W]
            rgb_image_single = rgb_image[0]      # [H, W, 3]
        else:
            # [H, W] -> ç›´æ¥å¤„ç†
            batch_size = 1
            depth_image_single = depth_image     # [H, W]
            rgb_image_single = rgb_image         # [H, W, 3]

        # 1. æ·±åº¦å›¾è½¬ç‚¹äº‘
        pointcloud = self.depth_converter(depth_image_single, rgb_image_single, key, train=train)

        # 2. æ·»åŠ batchç»´åº¦ [1, N, 9]
        pointcloud = jnp.expand_dims(pointcloud, axis=0)

        # 3. SegNNç¼–ç  (ä½¿ç”¨trainingæ¨¡å¼)
        features = self.segnn_encoder(pointcloud, variant='training')

        # 4. ç§»é™¤batchç»´åº¦å¹¶å±•å¹³ [N, C] -> [N*C]
        features = features.reshape(-1)

        # 5. ç“¶é¢ˆå±‚
        if self.bottleneck_dim is not None:
            features = self.bottleneck(features)
            features = self.layer_norm(features)
            features = nn.tanh(features)

        # 6. æ¢å¤batchç»´åº¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if batch_size > 1:
            # æ‰©å±•ç‰¹å¾ä»¥åŒ¹é…batchå¤§å°
            features = jnp.expand_dims(features, axis=0)
            features = jnp.repeat(features, batch_size, axis=0)

        return features


def create_segnn_encoder(
    input_points: int = 2048,
    num_stages: int = 3,
    embed_dim: int = 72,
    bottleneck_dim: int = 256,
    camera_params: Optional[dict] = None
) -> SegNNEncoder:
    """
    åˆ›å»ºSegNNç¼–ç å™¨çš„å·¥å‚å‡½æ•°

    Args:
        input_points: è¾“å…¥ç‚¹æ•°
        num_stages: ç¼–ç é˜¶æ®µæ•°
        embed_dim: åµŒå…¥ç»´åº¦
        bottleneck_dim: ç“¶é¢ˆç»´åº¦
        camera_params: ç›¸æœºå‚æ•°å­—å…¸

    Returns:
        SegNNç¼–ç å™¨å®ä¾‹
    """
    encoder_kwargs = {
        'input_points': input_points,
        'num_stages': num_stages,
        'embed_dim': embed_dim,
        'bottleneck_dim': bottleneck_dim,
    }

    if camera_params:
        encoder_kwargs.update({
            'camera_fx': camera_params.get('fx', 615.0),
            'camera_fy': camera_params.get('fy', 615.0),
            'camera_cx': camera_params.get('cx', 320.0),
            'camera_cy': camera_params.get('cy', 240.0),
        })

    return SegNNEncoder(**encoder_kwargs)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•SegNNç¼–ç å™¨é›†æˆ")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    key = jax.random.PRNGKey(42)
    H, W = 240, 320  # è¾ƒå°çš„åˆ†è¾¨ç‡ç”¨äºæµ‹è¯•

    depth_key, rgb_key, test_key = jax.random.split(key, 3)
    depth = jax.random.uniform(depth_key, (H, W), minval=0.5, maxval=1.5)
    rgb = jax.random.uniform(rgb_key, (H, W, 3), minval=0, maxval=255)

    # åˆ›å»ºç¼–ç å™¨
    encoder = create_segnn_encoder(
        input_points=512,  # è¾ƒå°‘ç‚¹æ•°ç”¨äºå¿«é€Ÿæµ‹è¯•
        num_stages=2,
        embed_dim=36,
        bottleneck_dim=128
    )

    # åˆå§‹åŒ–å‚æ•°
    init_key, apply_key = jax.random.split(test_key)
    params = encoder.init({'params': init_key, 'pointcloud_sampling': apply_key},
                         depth, rgb, train=True)

    # æ‰§è¡Œç¼–ç 
    features = encoder.apply(params, depth, rgb, train=True,
                           rngs={'pointcloud_sampling': apply_key})

    print(f"âœ“ è¾“å…¥æ·±åº¦å›¾å½¢çŠ¶: {depth.shape}")
    print(f"âœ“ è¾“å…¥RGBå›¾å½¢çŠ¶: {rgb.shape}")
    print(f"âœ“ è¾“å‡ºç‰¹å¾å½¢çŠ¶: {features.shape}")
    print(f"âœ“ ç‰¹å¾èŒƒå›´: [{jnp.min(features):.3f}, {jnp.max(features):.3f}]")

    print("\nğŸ¯ SegNNç¼–ç å™¨é›†æˆæˆåŠŸ!")
    print("ğŸ“‹ å‡†å¤‡é›†æˆåˆ°SAC agentä¸­...")